{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3255ba75",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Twitter Data for Brand Monitoring\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f725b7ec",
   "metadata": {},
   "source": [
    "\n",
    "### **Introduction**\n",
    "This notebook demonstrates the implementation of sentiment analysis on Twitter data for brand monitoring. \n",
    "It integrates data preprocessing, feature engineering, machine learning models, and visualization \n",
    "techniques to analyze sentiment trends and evaluate brand perception.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e255d",
   "metadata": {},
   "source": [
    "\n",
    "### **Data Preprocessing**\n",
    "- **Text Cleaning**: Remove noise such as URLs, mentions, hashtags, and special characters.\n",
    "- **Tokenization**: Split tweets into individual tokens.\n",
    "- **Stop Word Removal**: Remove common words that do not contribute to sentiment (e.g., \"and\", \"is\").\n",
    "- **Lemmatization**: Reduce words to their base or root form.\n",
    "\n",
    "#### Code Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb134930",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Example dataset\n",
    "data = {\n",
    "    'tweet': [\n",
    "        'I love the new iPhone! #Apple',\n",
    "        'Terrible customer service from Amazon. @Amazon',\n",
    "        'Netflix has great shows, but the app crashes too often.'\n",
    "    ],\n",
    "    'sentiment': ['positive', 'negative', 'neutral']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing function\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    # Remove URLs, mentions, hashtags, and special characters\n",
    "    tweet = re.sub(r\"http\\S+|@\\S+|#\\S+|[^A-Za-z0-9\\s]\", \"\", tweet)\n",
    "    tweet = tweet.lower()\n",
    "    tokens = word_tokenize(tweet)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['cleaned_tweet'] = df['tweet'].apply(preprocess_tweet)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2ab30",
   "metadata": {},
   "source": [
    "\n",
    "### **Feature Engineering**\n",
    "- Extract features such as tweet length, hashtag count, and mentions count.\n",
    "- Perform Named Entity Recognition (NER) to associate entities with sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(df['cleaned_tweet'])\n",
    "y = df['sentiment']\n",
    "\n",
    "# Named Entity Recognition Example\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities(tweet):\n",
    "    doc = nlp(tweet)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "df['entities'] = df['tweet'].apply(extract_entities)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6c41a9",
   "metadata": {},
   "source": [
    "\n",
    "### **Model Training**\n",
    "- Implement Logistic Regression, SVM, Decision Tree, and Random Forest.\n",
    "- Evaluate models using accuracy, precision, recall, and F1-score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df10b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=10)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# Model Evaluation\n",
    "print(\"Logistic Regression:\n",
    "\", classification_report(y_test, lr_pred))\n",
    "print(\"SVM:\n",
    "\", classification_report(y_test, svm_pred))\n",
    "print(\"Decision Tree:\n",
    "\", classification_report(y_test, dt_pred))\n",
    "print(\"Random Forest:\n",
    "\", classification_report(y_test, rf_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db3d28",
   "metadata": {},
   "source": [
    "\n",
    "### **Visualizations**\n",
    "- **Word Cloud**: Highlight common words in positive and negative tweets.\n",
    "- **Feature Importance**: Show most influential features for sentiment classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d546e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate word clouds\n",
    "positive_words = \" \".join(df[df['sentiment'] == 'positive']['cleaned_tweet'])\n",
    "negative_words = \" \".join(df[df['sentiment'] == 'negative']['cleaned_tweet'])\n",
    "\n",
    "# Positive Word Cloud\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(WordCloud(background_color='white').generate(positive_words))\n",
    "plt.axis('off')\n",
    "plt.title(\"Positive Sentiments Word Cloud\")\n",
    "plt.show()\n",
    "\n",
    "# Negative Word Cloud\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.imshow(WordCloud(background_color='white').generate(negative_words))\n",
    "plt.axis('off')\n",
    "plt.title(\"Negative Sentiments Word Cloud\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}